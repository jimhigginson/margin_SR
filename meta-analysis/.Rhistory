ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
theme_tufte() +
theme(legend.title  = element_blank())
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
summary_data
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = frozen.data, aes(V1, V2), fill = 'red', shape = 21)
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), fill = 'red', shape = 21)
theme_tufte() +
theme(legend.title  = element_blank())
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, fill = 'Summary estimate'), shape = 21)
theme_tufte() +
theme(legend.title  = element_blank())
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, fill = 'Summary estimate'), shape = 21)
theme_tufte() +
theme(legend.title  = element_blank())
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, fill = 'Summary estimate'), shape = 21) +
theme_tufte() +
theme(legend.title  = element_blank())
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, colour = 'Summary estimate'), fill = 'blue', shape = 21) +
theme_tufte() +
theme(legend.title  = element_blank())
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, colour = 'Summary estimate'), shape = 21) +
theme_tufte() +
theme(legend.title  = element_blank())
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2, colour = 'Summary ROC')) +
geom_polygon(data = confidence_region, aes(V1, V2, fill = '95% confidence interval'), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2, color = 'Summary estimate'), shape = 21) +
theme_tufte() +
theme(legend.title  = element_blank())
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2)) +
geom_polygon(data = confidence_region, aes(V1, V2), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), shape = 21) +
theme_tufte() +
theme(legend.title  = element_blank())
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2)) +
geom_polygon(data = confidence_region, aes(V1, V2), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), shape = 21) +
theme_tufte() +
labs(title = 'Summary ROC curve for frozen section studies')
xlab('False positive rate') +
ylab('Sensitivity')
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2)) +
geom_polygon(data = confidence_region, aes(V1, V2), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), shape = 21) +
theme_tufte() +
labs(title = 'Summary ROC curve for frozen section studies') +
xlab('False positive rate') +
ylab('Sensitivity')
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2)) +
geom_polygon(data = confidence_region, aes(V1, V2), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), shape = 21) +
theme_tufte() +
labs(title = 'Summary ROC curve for frozen section studies') +
xlab('False positive rate') +
ylab('Sensitivity')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mvtnorm)
library(ellipse)
library(mvmeta)
library(meta)
library(ggthemes)
drop_empty <- function(x) {!all(is.na(x))}
# function to be used below to drop any columns that are totally empty.
cols_to_keep <- c(
"Covidence #",
"Study ID",
"Title...3",
"First Author Name",
"Year of publication",
"Number of patients included",
"modality_group",
#   muting these columns whilst I work out the pivoting to keep it cleaner
#  "Number of margins included",
#  "Study design",
#  "HNSCC sub-sites included in study",
#  "HPV status of participants",
#  "Mean age",
#  "Population description",
#  "What intraoperative margin tool is being evaluated in this study?",
"Modality Diagnostic tool 1",
#  "Modality Diagnostic tool 2",
"True negatives Diagnostic tool 1",
"True positives Diagnostic tool 1",
"False negatives Diagnostic tool 1",
"False positives Diagnostic tool 1"
)
frozen.data <- read_csv('review_120729_20220223033858.csv') %>%
# This produces a very wide table, with repeated column titles for four diagnostic modalitiies, even though most papers will only discuss one.
select_if(drop_empty) %>%
select(cols_to_keep) %>%
rename(
"TN" = "True negatives Diagnostic tool 1",
"TP" = "True positives Diagnostic tool 1",
"FN" = "False negatives Diagnostic tool 1",
"FP" = "False positives Diagnostic tool 1"
)
sensitivity.logit <- metaprop(
frozen.data$TP,
frozen.data$TP + frozen.data$FN,
comb.fixed=FALSE,
comb.random=TRUE,
sm = 'PLOGIT',
method.ci = 'CP',
studlab = frozen.data$`Study ID`,
byvar = frozen.data$`modality_group`
)
specificity.logit <- metaprop(
frozen.data$TN,
frozen.data$TN + frozen.data$FP,
comb.fixed=FALSE,
comb.random=TRUE,
sm = 'PLOGIT',
method.ci = 'CP',
studlab = frozen.data$`Study ID`,
byvar = frozen.data$`modality_group`
)
print(sensitivity.logit, digits=3)
print(specificity.logit, digits=3)
forest(
sensitivity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Sensitivity'
)
forest(
specificity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Specificity'
)
DOR_model <- metabin(
TP,
TP+FP,
FN,
FN+TN,
sm='OR',
comb.fixed=FALSE,
comb.random=TRUE,
method='Inverse',
#studlab = 'Study ID',
byvar=modality_group,
data=frozen.data)
forest(DOR_model, digits=3, rightcols=c('effect', 'ci'), xlab ='Diagnostic Odds Ratio')
detach(package:meta)
library(mada)
#needs to be loaded after detaching meta as they clash apparently (see Shim2019)
forest(madad(frozen.data), type='sens', xlab='Sensitivity', snames=frozen.data$`Study ID`)
forest(madad(frozen.data), type='spec', xlab='Specificity', snames=frozen.data$`Study ID`)
forest(madauni(frozen.data))
fit <- reitsma(frozen.data, correction.control='single')
plot(fit, sroclwd = 2, xlim = c(0,1), ylim = c(0,1), main = "SROC curve (bivariate model) for Diagnostic Test Accuracy")
points(fpr(frozen.data), sens(frozen.data), pch=20)
legend("bottomright", c("data", "summary estimate", "AUC=0.906", "DOR=37.935", "Sensitivity=0.841", "Specificity=0.861"), pch = c(20,1,1000,1000,1000,1000) )
legend("bottomleft", c("SROC", "95% CI region"), lwd = c(2,1))
confidence_region <- as_tibble(ROCellipse(fit)$ROCellipse)
summary_data <- as_tibble(ROCellipse(fit)$fprsens)
sroc_curve <- as_tibble(sroc(fit)) %>%
add_row(fpr = 0, V2 = 0, .before = 1)
ggplot() +
geom_line(data = sroc_curve, aes(fpr, V2)) +
geom_polygon(data = confidence_region, aes(V1, V2), alpha = 0.3) +
geom_point(aes(fpr(frozen.data), sens(frozen.data)), size = 1) +
geom_point(data = summary_data, aes(V1, V2), shape = 21) +
theme_tufte() +
labs(title = 'Summary ROC curve for frozen section studies') +
xlab('False positive rate') +
ylab('Sensitivity')
forest(
sensitivity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Sensitivity'
)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mvtnorm)
library(ellipse)
library(mvmeta)
library(meta)
library(ggthemes)
drop_empty <- function(x) {!all(is.na(x))}
# function to be used below to drop any columns that are totally empty.
cols_to_keep <- c(
"Covidence #",
"Study ID",
"Title...3",
"First Author Name",
"Year of publication",
"Number of patients included",
"modality_group",
#   muting these columns whilst I work out the pivoting to keep it cleaner
#  "Number of margins included",
#  "Study design",
#  "HNSCC sub-sites included in study",
#  "HPV status of participants",
#  "Mean age",
#  "Population description",
#  "What intraoperative margin tool is being evaluated in this study?",
"Modality Diagnostic tool 1",
#  "Modality Diagnostic tool 2",
"True negatives Diagnostic tool 1",
"True positives Diagnostic tool 1",
"False negatives Diagnostic tool 1",
"False positives Diagnostic tool 1"
)
frozen.data <- read_csv('review_120729_20220223033858.csv') %>%
# This produces a very wide table, with repeated column titles for four diagnostic modalitiies, even though most papers will only discuss one.
select_if(drop_empty) %>%
select(cols_to_keep) %>%
rename(
"TN" = "True negatives Diagnostic tool 1",
"TP" = "True positives Diagnostic tool 1",
"FN" = "False negatives Diagnostic tool 1",
"FP" = "False positives Diagnostic tool 1"
)
sensitivity.logit <- metaprop(
frozen.data$TP,
frozen.data$TP + frozen.data$FN,
comb.fixed=FALSE,
comb.random=TRUE,
sm = 'PLOGIT',
method.ci = 'CP',
studlab = frozen.data$`Study ID`,
byvar = frozen.data$`modality_group`
)
specificity.logit <- metaprop(
frozen.data$TN,
frozen.data$TN + frozen.data$FP,
comb.fixed=FALSE,
comb.random=TRUE,
sm = 'PLOGIT',
method.ci = 'CP',
studlab = frozen.data$`Study ID`,
byvar = frozen.data$`modality_group`
)
print(sensitivity.logit, digits=3)
print(specificity.logit, digits=3)
forest(
sensitivity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Sensitivity'
)
forest(
specificity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Specificity'
)
DOR_model <- metabin(
TP,
TP+FP,
FN,
FN+TN,
sm='OR',
comb.fixed=FALSE,
comb.random=TRUE,
method='Inverse',
#studlab = 'Study ID',
byvar=modality_group,
data=frozen.data)
DOR_model <- metabin(
TP,
TP+FP,
FN,
FN+TN,
sm='OR',
comb.fixed=FALSE,
comb.random=TRUE,
method='Inverse',
studlab = 'Study ID',
byvar=modality_group,
data=frozen.data)
frozen.data
DOR_model <- metabin(
TP,
TP+FP,
FN,
FN+TN,
sm='OR',
comb.fixed=FALSE,
comb.random=TRUE,
method='Inverse',
studlab = `Study ID`,
byvar=modality_group,
data=frozen.data)
forest(
specificity.logit,
digits = 3,
rightcols = c('effect','ci'),
xlab = 'Specificity'
)
DOR_model <- metabin(
TP,
TP+FP,
FN,
FN+TN,
sm='OR',
comb.fixed=FALSE,
comb.random=TRUE,
method='Inverse',
studlab = `Study ID`,
byvar=modality_group,
data=frozen.data)
forest(DOR_model, digits=3, rightcols=c('effect', 'ci'), xlab ='Diagnostic Odds Ratio')
frozen.data %>%
mutate(
'sensitivity' = TP/(TP+FN)
)
frozen.data
frozen.data %>%
mutate(
sensitivity = TP/(TP+FN)
)
frozen.dahta
frozen.data
frozen.data <- frozen.data %>%
mutate(
sensitivity = TP/(TP+FN)
)
frozen.data
frozen.data$sensitivity
frozen.data <- frozen.data %>%
mutate(
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data
frozen.data$logit_sn
cor(frozen.data$logint_sn, frozen.data$logit_sp)
cor(frozen.data$logit_sn, frozen.data$logit_sp)
frozen.data <- frozen.data %>%
mutate(
TN = case_when(TN == 0 ~ 0.001),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data
frozen.data <- frozen.data %>%
mutate(
TN = if_else(TN == 0, 0.001, TN),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data
drop_empty <- function(x) {!all(is.na(x))}
# function to be used below to drop any columns that are totally empty.
cols_to_keep <- c(
"Covidence #",
"Study ID",
"Title...3",
"First Author Name",
"Year of publication",
"Number of patients included",
"modality_group",
#   muting these columns whilst I work out the pivoting to keep it cleaner
#  "Number of margins included",
#  "Study design",
#  "HNSCC sub-sites included in study",
#  "HPV status of participants",
#  "Mean age",
#  "Population description",
#  "What intraoperative margin tool is being evaluated in this study?",
"Modality Diagnostic tool 1",
#  "Modality Diagnostic tool 2",
"True negatives Diagnostic tool 1",
"True positives Diagnostic tool 1",
"False negatives Diagnostic tool 1",
"False positives Diagnostic tool 1"
)
frozen.data <- read_csv('review_120729_20220223033858.csv') %>%
# This produces a very wide table, with repeated column titles for four diagnostic modalitiies, even though most papers will only discuss one.
select_if(drop_empty) %>%
select(cols_to_keep) %>%
rename(
"TN" = "True negatives Diagnostic tool 1",
"TP" = "True positives Diagnostic tool 1",
"FN" = "False negatives Diagnostic tool 1",
"FP" = "False positives Diagnostic tool 1"
)
frozen.data <- frozen.data %>%
mutate(
TN = if_else(TN == 0, 0.001, TN),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data
frozen.data <- frozen.data %>%
mutate(
FN = if_else(FN == 0, 0.001, FN),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data
frozen.data <- frozen.data %>%
mutate(
FN = if_else(FN == 0, 0.001, FN),
FP = if_else(FP == 0, 0.001, FP),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
frozen.data <- frozen.data %>%
mutate(
FN = if_else(FN == 0, 0.001, FN),
FP = if_else(FP == 0, 0.001, FP),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
correlation = cor(frozen.data$logit_sn, frozen.data$logit_sp)
correlation
DOR_model
library(meta)
metareg(DOR_model, modality_group, method.tau = 'REML', digits = 3)
library(meta)
metareg(DOR_model, modality_group, method.tau = 'REML', digits = 3)
diagnostic_metaregression <- metareg(DOR_model, modality_group, method.tau = 'REML', digits = 3)
diagnostic_metaregression
diagnostic_heterogeneity <- frozen.data %>% # creates a dataframe suitable for logit transformation
mutate(
FN = if_else(FN == 0, 0.001, FN),
FP = if_else(FP == 0, 0.001, FP),
sensitivity = TP/(TP+FN),
specificity = TN/(TN+FP),
logit_sn = sensitivity/(1-sensitivity),
logit_sp = specificity/(1-specificity)
)
correlation = cor(frozen.data$logit_sn, frozen.data$logit_sp)
diagnostic_heterogeneity
