---
title: "Intraoperative Margin Assessment Systematic Review and Meta-analysis"
author: "Jim Higginson"
date: "15/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mvtnorm)
library(ellipse)
library(mvmeta)
library(meta)

```

## Data input

Getting the data in

```{r input data}

frozen.data <- read_csv('test_stats.csv') %>% 
# This produces a very wide table, with repeated column titles for four diagnostic modalitiies, even though most papers will only discuss one. 
select(!ends_with(c("2", "3", "4")))
# for the initial run with just two studies, this removes modalities 2/3/4

```

## Univariate analysis

Hutan recommended using two or three different R packages to evaluate the results to ensure that they are believable.
I'm running this practice based on shim et al 2019 tutorial

```{r}
sensitivity.logit <- metaprop(
  frozen.data$TP, 
  frozen.data$TP + frozen.data$FN,
  comb.fixed=FALSE,
  comb.random=TRUE,
  sm = 'PLOGIT',
  method.ci = 'CP'#,
  # studlab = frozen.data$`Study ID`
)

specificity.logit <- metaprop(
  frozen.data$TN,
  frozen.data$TN + frozen.data$FP,
    comb.fixed=FALSE,
  comb.random=TRUE,
  sm = 'PLOGIT',
  method.ci = 'CP'#,
  #studlab = frozen.data$`Study ID`
)

print(sensitivity.logit, digits=3)
print(specificity.logit, digits=3)
```


## forest plot


```{r pressure, echo=FALSE}
forest(
  sensitivity.logit,
  digits = 3,
  rightcols = c('effect','ci'),
  xlab = 'Sensitivity'
)

forest(
  specificity.logit,
  digits = 3,
  rightcols = c('effect','ci'),
  xlab = 'Specificity'
)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# Diagnostic odds ratio

```{r}
DOR_model <- metabin(
  TP,
  TP+FP,
  FN,
  FN+TN, 
  sm='OR', 
  comb.fixed=FALSE,
  comb.random=TRUE, 
  method='Inverse', 
  study, 
  #byvar=g, 
  data=frozen.data)
```
```{r}
forest(DOR_model, digits=3, rightcols=c('effect', 'ci'), xlab ='Diagnostic Odds Ratio')
```


```{r bivariate analysis}
detach(package:meta)
library(mada) 
#needs to be loaded after detaching meta as they clash apparently (see Shim2019)
```

Now generate the same forest plots using `mada` instead of `meta` - the only difference being that they don't show the overall effec size of the summary stats.

```{r}
forest(madad(frozen.data), type='sens', xlab='Sensitivity', snames=frozen.data$study)
```

Now create the bivariate model with the `reitsma' function
